# Prueba TÃ©cnica â€“ Jr. Machine Learning Engineer en Roda

> Microservicio de datos en GCP (Cloud Run) con ingesta desde fuente pÃºblica, transformaciÃ³n y carga a PostgreSQL local. Este README documenta arquitectura, decisiones, despliegue y pruebas.

---

## ðŸ§­ Resumen

* **Objetivo**: Ingerir datos pÃºblicos relevantes para Roda, transformarlos (enriquecimiento/agregaciÃ³n) y **cargarlos a PostgreSQL local**. El servicio **corre en Cloud Run** (Docker + Artifact Registry) y puede ejecutarse **batch** (Scheduler) o **real-time** (endpoint HTTP) segÃºn se elija.
* **Stack sugerido**: Python 3.10+, FastAPI (opcional), Pandas/PyArrow, SQLAlchemy (async + `asyncpg`), Docker, Google Cloud Run, Artifact Registry.

> El foco estÃ¡ en **infra** (GCP/Cloud Run) y en una **transformaciÃ³n no trivial** que responda una pregunta Ãºtil para Roda (movilidad, gig economy, seguridad, clima, energÃ­a, etc.).

---

## ðŸ—ï¸ Arquitectura

```
[Fuente PÃºblica] --(HTTP/CSV/JSON/GeoJSON/BigQuery PÃºblico)--> [Cloud Run Service]
                                    |                              |
                                    | TransformaciÃ³n (pandas/SQL)  |  
                                    v                              v
                             [Opcional: BigQuery]            [PostgreSQL Local]

Modo batch: Cloud Scheduler (HTTP) ---> Cloud Run (con parÃ¡metros)
Modo real-time: Cliente (curl/httpie) ---> Endpoint HTTP (valida payload)
```

* **Cloud Run**: contenedor stateless, escalable bajo demanda.
* **Artifact Registry**: almacenamiento de imÃ¡genes Docker.
* **PostgreSQL local**: destino final (conexiÃ³n segura vÃ­a internet o tÃºnel; para pruebas locales se puede exponer en `localhost`).
* **Opcional**: BigQuery para persistencia analÃ­tica adicional.

---

## ðŸŽ¯ DecisiÃ³n de ejecuciÃ³n (elige 1 y ajusta)

### OpciÃ³n A â€“ Batch (recomendado para MVP)

* **CuÃ¡ndo**: fuentes pÃºblicas con ventanas diarias/horarias; pipelines repetibles.
* **Por quÃ©**: mÃ¡s simple de operar y controlar costos. IdÃ³neo para cÃ¡lculos agregados y puntuaciones periÃ³dicas.
* **CÃ³mo**: Cloud Scheduler â†’ HTTP a Cloud Run con parÃ¡metros (rango de fechas, ciudad, etc.).

### OpciÃ³n B â€“ Real-time (si necesitas endpoint)

* **CuÃ¡ndo**: validaciones bajo demanda, consultas ad-hoc, webhooks.
* **Por quÃ©**: visibilidad inmediata para pruebas y demos.
* **CÃ³mo**: FastAPI/Starlette exponiendo `POST /run` y `GET /health`.

> Justifica brevemente tu elecciÃ³n en este README.

---

## ðŸ“š SelecciÃ³n de fuente de datos (guÃ­a)

Escoge **1+** fuentes con aplicaciÃ³n real para Roda y documÃ©ntalo:

* **Movilidad**: ciclorutas/accidentes/transporte (OSM/Overpass, datos abiertos de BogotÃ¡, etc.).
* **EconomÃ­a/Ingreso**: DANE/INEGI/World Bank (empleo independiente, estratos, densidad negocio).
* **Seguridad**: robos de bici/moto por zona/fecha.
* **Clima/EnergÃ­a**: precipitaciÃ³n/temperatura (impacto en demanda), tarifas energÃ­a.
* **Comercio**: densidad de restaurantes/tiendas (Ãºltima milla).

En `docs/fuente.md` explica: origen, licenciamiento, cobertura temporal/espacial, campos, calidad y **por quÃ© ayuda a Roda**.

---

## ðŸ§  TransformaciÃ³n mÃ­nima requerida

Incluye **al menos una** de estas operaciones (o combinaciones):

* **Join geogrÃ¡fico** (p.ej., puntos a barrios/localidades).
* **Ventanas** (rolling, ranking por zona/hora).
* **Scoring heurÃ­stico** (ej.: potencial de demanda por barrio con ponderaciones).
* **Feature engineering** (densidades, Ã­ndices, normalizaciones).
* **DetecciÃ³n simple de outliers** (IQR, z-score) si aplica.

Documenta la lÃ³gica en `docs/transformacion.md` con fÃ³rmulas/casos.

---

## ðŸ“¦ Estructura del repositorio

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # FastAPI/CLI entrypoint (batch o real-time)
â”‚   â”œâ”€â”€ ingest.py              # Descarga/lectura de fuente(s) pÃºblicas
â”‚   â”œâ”€â”€ transform.py           # Limpieza, joins, features, scoring
â”‚   â”œâ”€â”€ load_pg.py             # Carga a PostgreSQL (SQLAlchemy async)
â”‚   â”œâ”€â”€ db.py                  # ConexiÃ³n/engine y helpers
â”‚   â””â”€â”€ schemas.py             # Pydantic (si endpoint) / modelos internos
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ init.sql               # DDL destino en Postgres
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ sample_payload.json    # Ejemplo request para /run (si real-time)
â”‚   â””â”€â”€ sample_response.json   # Ejemplo de respuesta
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ fuente.md              # DescripciÃ³n detallada de la(s) fuente(s)
â”‚   â”œâ”€â”€ transformacion.md      # DiseÃ±o de features/joins/score
â”‚   â””â”€â”€ arquitectura.md        # Diagramas y decisiones
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ Makefile                   # Atajos: test, build, run, deploy, seed
â””â”€â”€ README.md
```

---

## ðŸ”‘ Variables de entorno

Crea `.env` (no lo subas) a partir de `.env.example`:

```
# Base de datos local
PG_HOST=localhost
PG_PORT=5432
PG_DB=roda
PG_USER=roda
PG_PASSWORD=roda
PG_SSLMODE=disable

# ParÃ¡metros de ejecuciÃ³n
REGION=bogota
START_DATE=2025-01-01
END_DATE=2025-01-31

# Opcional BigQuery
BQ_PROJECT_ID=<tu_proyecto>
BQ_DATASET=roda_analytics
```

---

## ðŸ—„ï¸ Esquema destino (PostgreSQL)

Archivo `sql/init.sql` (ajusta nombres/campos segÃºn tu fuente):

```sql
CREATE SCHEMA IF NOT EXISTS roda;

CREATE TABLE IF NOT EXISTS roda.demanda_zona (
  run_id           TEXT,
  region           TEXT,
  zona_id          TEXT,
  zona_nombre      TEXT,
  fecha            DATE,
  hora             INT,
  densidad_comercio NUMERIC,
  clima_lluvia     NUMERIC,
  robos_bici       INT,
  score_demanda    NUMERIC,
  inserted_at      TIMESTAMP DEFAULT NOW(),
  PRIMARY KEY (run_id, region, zona_id, fecha, hora)
);
```

* **Clave primaria compuesta** para **idempotencia** (evita duplicados por reintentos).
* Agrega Ã­ndices segÃºn tus consultas (`region, fecha`, etc.).

---

## â–¶ï¸ EjecuciÃ³n local (sin GCP)

1. **Crear y poblar Postgres**

```bash
psql -h $PG_HOST -U $PG_USER -d $PG_DB -f sql/init.sql
```

2. **Crear entorno y deps**

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

3. **Run batch por CLI**

```bash
export $(grep -v '^#' .env | xargs)
python -m app.main --mode batch --region "$REGION" --start "$START_DATE" --end "$END_DATE"
```

4. **Run API (real-time)**

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8080
# Healthcheck
curl -s http://localhost:8080/health
# Ejecutar
http POST :8080/run region=$REGION start=$START_DATE end=$END_DATE
```

---

## ðŸ³ Docker (local)

```bash
# Build
docker build -t roda-microservice:local .

# Run con .env y red para llegar a Postgres local
docker run --rm -it \
  --env-file .env \
  --network host \
  roda-microservice:local
```

> En Windows sin `--network host`, mapea `-p 8080:8080` y ajusta `PG_HOST` a la IP de tu host.

---

## â˜ï¸ Despliegue en GCP (Cloud Run + Artifact Registry)

> Requiere tener el **SDK de GCP** configurado y facturaciÃ³n activa.

```bash
# Variables
PROJECT_ID=<tu_proyecto>
REGION_GCP=us-central1
REPO=roda-repo
IMAGE=roda-microservice

# 1) Habilitar servicios (una vez)
gcloud services enable artifactregistry.googleapis.com run.googleapis.com

# 2) Crear repo de contenedores (una vez)
gcloud artifacts repositories create $REPO \
  --repository-format=docker \
  --location=$REGION_GCP \
  --description="Roda microservice images"

# 3) Build & Push
gcloud builds submit --tag $REGION_GCP-docker.pkg.dev/$PROJECT_ID/$REPO/$IMAGE:latest .

# 4) Deploy a Cloud Run
gcloud run deploy $IMAGE \
  --image $REGION_GCP-docker.pkg.dev/$PROJECT_ID/$REPO/$IMAGE:latest \
  --platform managed \
  --region $REGION_GCP \
  --allow-unauthenticated \
  --set-env-vars PG_HOST=$PG_HOST,PG_PORT=$PG_PORT,PG_DB=$PG_DB,PG_USER=$PG_USER,PG_PASSWORD=$PG_PASSWORD,PG_SSLMODE=$PG_SSLMODE

# 5) Obtener URL
SERVICE_URL=$(gcloud run services describe $IMAGE --region $REGION_GCP --format='value(status.url)')
echo $SERVICE_URL
```

> **Seguridad**: considera usar **Secret Manager** para credenciales de Postgres (evita exponerlas en variables pÃºblicas/Cloud Run si es pÃºblico).

---

## â±ï¸ ProgramaciÃ³n (Batch) con Cloud Scheduler

```bash
# Programar ejecuciÃ³n diaria 06:00 (hora de la regiÃ³n del servicio)
SVC_URL=$SERVICE_URL

# Ejemplo de payload
cat > examples/scheduler_payload.json << 'EOF'
{
  "region": "bogota",
  "start": "2025-01-01",
  "end": "2025-01-31"
}
EOF

# Crear job Scheduler (una vez)
gcloud scheduler jobs create http roda-daily \
  --schedule="0 6 * * *" \
  --uri="$SVC_URL/run" \
  --http-method=POST \
  --message-body-from-file=examples/scheduler_payload.json \
  --headers="Content-Type=application/json"
```

---

## ðŸ”Œ Endpoints (si usas FastAPI)

* `GET /health` â†’ 200 OK
* `POST /run` â†’ Ejecuta ingesta â†’ transformaciÃ³n â†’ carga a Postgres

  * **Body** (JSON): `{ "region": "bogota", "start": "YYYY-MM-DD", "end": "YYYY-MM-DD" }`
  * **200**: `{ "run_id": "...", "rows_loaded": 1234 }`
  * **4xx/5xx**: mensaje de error con trazabilidad

Incluye ejemplos en `/examples`.

---

## ðŸ§ª Tests & calidad

* Pruebas unitarias de funciones de transformaciÃ³n.
* Validaciones de esquema (tipos/campos obligatorios).
* **Idempotencia**: reintentos no deben duplicar.
* **Logs estructurados** (JSON) con `run_id`, `region`, `rangos`, `rows_loaded`.

Ejemplo (Makefile):

```make
.PHONY: test fmt lint

test:
	pytest -q
fmt:
	ruff check --fix . && black .
lint:
	ruff check . && black --check .
```

---

## ðŸ§© Plus opcionales

* **BigQuery**: escribir dataframe transformado en `BQ_PROJECT_ID:BQ_DATASET.tabla`, Ãºtil para BI.
* **Workflows**: orquestar pasos (ingest â†’ transform â†’ load).
* **Terraform**: reproducir infra (Artifact Registry, Cloud Run, Scheduler, permisos).

Documenta cualquier plus en `docs/arquitectura.md`.

---

## ðŸ§¯ Troubleshooting

* **`permission denied` al desplegar**: verifica `gcloud auth login` y `roles/run.admin`, `roles/artifactregistry.admin`.
* **`cannot connect to Postgres`**: revisa firewall, `PG_HOST`, `PG_SSLMODE`, y si Cloud Run puede alcanzar tu DB (exponer temporalmente, tÃºnel, o usa un **Cloud SQL** como alternativa para demo).
* **Timeouts en ingesta**: aÃ±ade paginaciÃ³n/reintentos, timeouts y lÃ­mites de tamaÃ±o.
* **Memoria/CPU en Cloud Run**: sube `--memory` o `--cpu` en el deploy si transformaciones pesadas.

---

## âœ… Checklist de entrega

* [ ] Cloud Run **activo** con logs y evidencias (capturas o URL ofuscada en `docs/`)
* [ ] **Fuente** documentada y justificada (por quÃ© sirve a Roda)
* [ ] TransformaciÃ³n **no trivial** explicada
* [ ] **Carga a Postgres** demostrada (conteo de filas, esquema)
* [ ] README claro con **cÃ³mo correr local** y **cÃ³mo desplegar**
* [ ] `/examples` con payload y respuesta
* [ ] `sql/init.sql` incluido
* [ ] Opcional: BigQuery / Scheduler / Terraform

---

## ðŸ“« Entrega

EnvÃ­a el enlace del repo y notas de despliegue a **[santiago@roda.xyz](mailto:santiago@roda.xyz)** con asunto: **Prueba TÃ©cnica â€“ Jr ML Engineer**. Tiempo sugerido: **1â€“3 dÃ­as efectivos**. Prioriza un servicio que **funcione** y decisiones bien **justificadas**.

---

## ðŸ“„ Licencia

MIT (o agrega la que prefieras).

---

**Â¡Gracias!** âš¡ï¸ðŸš² Conviertes datos abiertos en decisiones que mejoran ingresos, reducen costos y hacen la vida urbana mÃ¡s fÃ¡cil.
